name: Daily HK Job Scrape

on:
  schedule:
    - cron: '0 0 * * *'   # midnight UTC = 8am HKT
  workflow_dispatch:        # allow manual trigger from GitHub UI

jobs:
  scrape-and-notify:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: hk-job-aggregator

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: hk-job-aggregator/requirements.txt

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Scrape jobs
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
        run: python scrape_all.py --no-descriptions

      - name: Score new jobs
        # continue even if scorer fails â€” emailer will show unscored table
        continue-on-error: true
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: python matcher.py

      - name: Send digest email
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          GMAIL_ADDRESS: ${{ secrets.GMAIL_ADDRESS }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
          NOTIFY_EMAIL: ${{ secrets.NOTIFY_EMAIL }}
        run: python emailer.py
